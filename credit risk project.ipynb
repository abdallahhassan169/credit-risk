{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\abdal\\anaconda3\\lib\\site-packages\\numpy\\_distributor_init.py:30: UserWarning: loaded more than 1 DLL from .libs:\n",
      "C:\\Users\\abdal\\anaconda3\\lib\\site-packages\\numpy\\.libs\\libopenblas.PYQHXLVVQ7VESDPUVUADXEVJOBGHJPAY.gfortran-win_amd64.dll\n",
      "C:\\Users\\abdal\\anaconda3\\lib\\site-packages\\numpy\\.libs\\libopenblas.WCDJNK7YVMPZQ2ME2ZZHJJRJ3JIKNDB7.gfortran-win_amd64.dll\n",
      "  warnings.warn(\"loaded more than 1 DLL from .libs:\"\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>income</th>\n",
       "      <th>age</th>\n",
       "      <th>loan</th>\n",
       "      <th>default</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>66155.925095</td>\n",
       "      <td>59.017015</td>\n",
       "      <td>8106.532131</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>34415.153966</td>\n",
       "      <td>48.117153</td>\n",
       "      <td>6564.745018</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>57317.170063</td>\n",
       "      <td>63.108049</td>\n",
       "      <td>8020.953296</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>42709.534201</td>\n",
       "      <td>45.751972</td>\n",
       "      <td>6103.642260</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>66952.688845</td>\n",
       "      <td>18.584336</td>\n",
       "      <td>8770.099235</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1995</th>\n",
       "      <td>59221.044874</td>\n",
       "      <td>48.518179</td>\n",
       "      <td>1926.729397</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1996</th>\n",
       "      <td>69516.127573</td>\n",
       "      <td>23.162104</td>\n",
       "      <td>3503.176156</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1997</th>\n",
       "      <td>44311.449262</td>\n",
       "      <td>28.017167</td>\n",
       "      <td>5522.786693</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1998</th>\n",
       "      <td>43756.056605</td>\n",
       "      <td>63.971796</td>\n",
       "      <td>1622.722598</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1999</th>\n",
       "      <td>69436.579552</td>\n",
       "      <td>56.152617</td>\n",
       "      <td>7378.833599</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2000 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            income        age         loan  default\n",
       "0     66155.925095  59.017015  8106.532131        0\n",
       "1     34415.153966  48.117153  6564.745018        0\n",
       "2     57317.170063  63.108049  8020.953296        0\n",
       "3     42709.534201  45.751972  6103.642260        0\n",
       "4     66952.688845  18.584336  8770.099235        1\n",
       "...            ...        ...          ...      ...\n",
       "1995  59221.044874  48.518179  1926.729397        0\n",
       "1996  69516.127573  23.162104  3503.176156        0\n",
       "1997  44311.449262  28.017167  5522.786693        1\n",
       "1998  43756.056605  63.971796  1622.722598        0\n",
       "1999  69436.579552  56.152617  7378.833599        0\n",
       "\n",
       "[2000 rows x 4 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#import libs\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "#read dataset\n",
    "df=pd.read_csv('original.csv')\n",
    "drops=['clientid']\n",
    "df.drop(drops,inplace=True,axis=1)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "income     283\n",
      "age        283\n",
      "loan       283\n",
      "default    283\n",
      "dtype: int64\n",
      "income     1717\n",
      "age        1714\n",
      "loan       1717\n",
      "default    1717\n",
      "dtype: int64\n",
      "income     False\n",
      "age         True\n",
      "loan       False\n",
      "default    False\n",
      "dtype: bool\n"
     ]
    }
   ],
   "source": [
    "#dataset analysis\n",
    "print(df[df['default']==1].count()) #//283\n",
    "print(df[df['default']==0].count()) #//1717 (unbalanced data............)\n",
    "print(df.isnull().any()) #//null values in age column only\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          income        age         loan  default\n",
      "15  50501.726689 -28.218361  3977.287432        0\n",
      "21  32197.620701 -52.423280  4244.057136        0\n",
      "26  63287.038908 -36.496976  9595.286289        0\n",
      "Empty DataFrame\n",
      "Columns: [income, age, loan, default]\n",
      "Index: []\n",
      "Empty DataFrame\n",
      "Columns: [income, age, loan, default]\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "print(df[df['age']<0])#negative values only here\n",
    "print(df[df['loan']<0])\n",
    "print(df[df['income']<0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       59.017015\n",
       "1       48.117153\n",
       "2       63.108049\n",
       "3       45.751972\n",
       "4       18.584336\n",
       "          ...    \n",
       "1995    48.518179\n",
       "1996    23.162104\n",
       "1997    28.017167\n",
       "1998    63.971796\n",
       "1999    56.152617\n",
       "Name: age, Length: 2000, dtype: float64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#remove negative values from age column\n",
    "df['age']=np.where(df['age']<0,df['age']*-1,df['age'])\n",
    "df['age']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       59.017015\n",
       "1       48.117153\n",
       "2       63.108049\n",
       "3       45.751972\n",
       "4       18.584336\n",
       "          ...    \n",
       "1995    48.518179\n",
       "1996    23.162104\n",
       "1997    28.017167\n",
       "1998    63.971796\n",
       "1999    56.152617\n",
       "Name: age, Length: 2000, dtype: float64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# impute dataset and replace null values\n",
    "df['age'].fillna(df['age'].mean(),inplace=True)\n",
    "df['age']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>income</th>\n",
       "      <th>age</th>\n",
       "      <th>loan</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>66155.925095</td>\n",
       "      <td>59.017015</td>\n",
       "      <td>8106.532131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>34415.153966</td>\n",
       "      <td>48.117153</td>\n",
       "      <td>6564.745018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>57317.170063</td>\n",
       "      <td>63.108049</td>\n",
       "      <td>8020.953296</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>42709.534201</td>\n",
       "      <td>45.751972</td>\n",
       "      <td>6103.642260</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>66952.688845</td>\n",
       "      <td>18.584336</td>\n",
       "      <td>8770.099235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1995</th>\n",
       "      <td>59221.044874</td>\n",
       "      <td>48.518179</td>\n",
       "      <td>1926.729397</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1996</th>\n",
       "      <td>69516.127573</td>\n",
       "      <td>23.162104</td>\n",
       "      <td>3503.176156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1997</th>\n",
       "      <td>44311.449262</td>\n",
       "      <td>28.017167</td>\n",
       "      <td>5522.786693</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1998</th>\n",
       "      <td>43756.056605</td>\n",
       "      <td>63.971796</td>\n",
       "      <td>1622.722598</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1999</th>\n",
       "      <td>69436.579552</td>\n",
       "      <td>56.152617</td>\n",
       "      <td>7378.833599</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2000 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            income        age         loan\n",
       "0     66155.925095  59.017015  8106.532131\n",
       "1     34415.153966  48.117153  6564.745018\n",
       "2     57317.170063  63.108049  8020.953296\n",
       "3     42709.534201  45.751972  6103.642260\n",
       "4     66952.688845  18.584336  8770.099235\n",
       "...            ...        ...          ...\n",
       "1995  59221.044874  48.518179  1926.729397\n",
       "1996  69516.127573  23.162104  3503.176156\n",
       "1997  44311.449262  28.017167  5522.786693\n",
       "1998  43756.056605  63.971796  1622.722598\n",
       "1999  69436.579552  56.152617  7378.833599\n",
       "\n",
       "[2000 rows x 3 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#split dataset into features and label\n",
    "X=df.iloc[:,:-1]\n",
    "y=df.iloc[:,-1]\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([4.72271990e+01, 1.69902240e+03, 5.93395636e+05]),\n",
       " array([6.32170996e-12, 0.00000000e+00, 0.00000000e+00]))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_selection import chi2\n",
    "chi2(X,y)\n",
    "#all features are relative to the output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[343   5]\n",
      " [ 18  34]]\n"
     ]
    }
   ],
   "source": [
    "#test the model without cluster_num paramter\n",
    "X_wc=X\n",
    "# Splitting the dataset into the Training set and Test set\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_wc_train, X_wc_test, y_train, y_test = train_test_split(X_wc, y, test_size = 0.2, random_state = 0)\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler \n",
    "sc=StandardScaler()\n",
    "X_train=sc.fit_transform(X_wc_train)\n",
    "X_test=sc.fit_transform(X_wc_test)\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "model = LogisticRegression()\n",
    "\n",
    "model.fit(X_wc_train, y_train)\n",
    "\n",
    "y_pred=model.predict(X_wc_test)\n",
    "# Making the Confusion Matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print(cm)\n",
    "#accuarcy without cluster_number is 94.1%\n",
    "#recall is 95%\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>income</th>\n",
       "      <th>age</th>\n",
       "      <th>loan</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>582</th>\n",
       "      <td>30991.431924</td>\n",
       "      <td>34.010026</td>\n",
       "      <td>4589.267265</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159</th>\n",
       "      <td>31847.853719</td>\n",
       "      <td>41.416336</td>\n",
       "      <td>2913.769931</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1827</th>\n",
       "      <td>24112.499394</td>\n",
       "      <td>35.971338</td>\n",
       "      <td>3285.499948</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>318</th>\n",
       "      <td>43777.518480</td>\n",
       "      <td>20.010928</td>\n",
       "      <td>3601.299685</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>708</th>\n",
       "      <td>40334.616734</td>\n",
       "      <td>45.886542</td>\n",
       "      <td>6808.869955</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>835</th>\n",
       "      <td>29496.594127</td>\n",
       "      <td>54.665821</td>\n",
       "      <td>2216.975334</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1216</th>\n",
       "      <td>31044.391757</td>\n",
       "      <td>49.935868</td>\n",
       "      <td>4465.872769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1653</th>\n",
       "      <td>48445.113124</td>\n",
       "      <td>38.979568</td>\n",
       "      <td>8733.442215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>559</th>\n",
       "      <td>53741.371019</td>\n",
       "      <td>49.729433</td>\n",
       "      <td>6513.150125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>684</th>\n",
       "      <td>55116.234515</td>\n",
       "      <td>41.468885</td>\n",
       "      <td>10284.606786</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1600 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            income        age          loan\n",
       "582   30991.431924  34.010026   4589.267265\n",
       "159   31847.853719  41.416336   2913.769931\n",
       "1827  24112.499394  35.971338   3285.499948\n",
       "318   43777.518480  20.010928   3601.299685\n",
       "708   40334.616734  45.886542   6808.869955\n",
       "...            ...        ...           ...\n",
       "835   29496.594127  54.665821   2216.975334\n",
       "1216  31044.391757  49.935868   4465.872769\n",
       "1653  48445.113124  38.979568   8733.442215\n",
       "559   53741.371019  49.729433   6513.150125\n",
       "684   55116.234515  41.468885  10284.606786\n",
       "\n",
       "[1600 rows x 3 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_wc_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "50/50 - 1s - loss: 1509.7219 - acc: 0.7519 - val_loss: 711.6372 - val_acc: 0.8700\n",
      "Epoch 2/150\n",
      "50/50 - 0s - loss: 1134.4917 - acc: 0.7412 - val_loss: 437.0099 - val_acc: 0.8700\n",
      "Epoch 3/150\n",
      "50/50 - 0s - loss: 772.7203 - acc: 0.7594 - val_loss: 327.6485 - val_acc: 0.8700\n",
      "Epoch 4/150\n",
      "50/50 - 0s - loss: 556.0739 - acc: 0.7575 - val_loss: 205.5060 - val_acc: 0.8700\n",
      "Epoch 5/150\n",
      "50/50 - 0s - loss: 431.4484 - acc: 0.7569 - val_loss: 152.3556 - val_acc: 0.8700\n",
      "Epoch 6/150\n",
      "50/50 - 0s - loss: 339.6410 - acc: 0.7606 - val_loss: 121.7284 - val_acc: 0.8700\n",
      "Epoch 7/150\n",
      "50/50 - 0s - loss: 278.7850 - acc: 0.7550 - val_loss: 85.4352 - val_acc: 0.8700\n",
      "Epoch 8/150\n",
      "50/50 - 0s - loss: 208.9952 - acc: 0.7588 - val_loss: 69.2840 - val_acc: 0.8700\n",
      "Epoch 9/150\n",
      "50/50 - 0s - loss: 146.6050 - acc: 0.7869 - val_loss: 48.2344 - val_acc: 0.8700\n",
      "Epoch 10/150\n",
      "50/50 - 0s - loss: 155.7243 - acc: 0.7619 - val_loss: 31.1276 - val_acc: 0.8700\n",
      "Epoch 11/150\n",
      "50/50 - 0s - loss: 104.3080 - acc: 0.7700 - val_loss: 25.3273 - val_acc: 0.8700\n",
      "Epoch 12/150\n",
      "50/50 - 0s - loss: 96.3140 - acc: 0.7638 - val_loss: 20.7662 - val_acc: 0.8700\n",
      "Epoch 13/150\n",
      "50/50 - 0s - loss: 75.3329 - acc: 0.7644 - val_loss: 17.7735 - val_acc: 0.8700\n",
      "Epoch 14/150\n",
      "50/50 - 0s - loss: 60.5279 - acc: 0.7594 - val_loss: 12.9922 - val_acc: 0.8700\n",
      "Epoch 15/150\n",
      "50/50 - 0s - loss: 58.0641 - acc: 0.7588 - val_loss: 7.5224 - val_acc: 0.8700\n",
      "Epoch 16/150\n",
      "50/50 - 0s - loss: 47.7069 - acc: 0.7738 - val_loss: 5.3967 - val_acc: 0.8700\n",
      "Epoch 17/150\n",
      "50/50 - 0s - loss: 35.6669 - acc: 0.7638 - val_loss: 4.2118 - val_acc: 0.8700\n",
      "Epoch 18/150\n",
      "50/50 - 0s - loss: 30.9445 - acc: 0.7875 - val_loss: 2.2490 - val_acc: 0.8700\n",
      "Epoch 19/150\n",
      "50/50 - 0s - loss: 27.7502 - acc: 0.7719 - val_loss: 2.5945 - val_acc: 0.8700\n",
      "Epoch 20/150\n",
      "50/50 - 0s - loss: 23.6276 - acc: 0.7806 - val_loss: 1.5168 - val_acc: 0.8700\n",
      "Epoch 21/150\n",
      "50/50 - 0s - loss: 20.5164 - acc: 0.7694 - val_loss: 0.9428 - val_acc: 0.8700\n",
      "Epoch 22/150\n",
      "50/50 - 0s - loss: 19.8677 - acc: 0.7744 - val_loss: 0.5758 - val_acc: 0.8700\n",
      "Epoch 23/150\n",
      "50/50 - 0s - loss: 14.7560 - acc: 0.7831 - val_loss: 0.3858 - val_acc: 0.8700\n",
      "Epoch 24/150\n",
      "50/50 - 0s - loss: 15.0772 - acc: 0.7837 - val_loss: 0.3921 - val_acc: 0.8700\n",
      "Epoch 25/150\n",
      "50/50 - 0s - loss: 13.8082 - acc: 0.7862 - val_loss: 0.5007 - val_acc: 0.8700\n",
      "Epoch 26/150\n",
      "50/50 - 0s - loss: 13.4591 - acc: 0.7763 - val_loss: 0.3675 - val_acc: 0.8700\n",
      "Epoch 27/150\n",
      "50/50 - 0s - loss: 11.2610 - acc: 0.7994 - val_loss: 0.3655 - val_acc: 0.8700\n",
      "Epoch 28/150\n",
      "50/50 - 0s - loss: 8.2686 - acc: 0.8062 - val_loss: 0.3622 - val_acc: 0.8700\n",
      "Epoch 29/150\n",
      "50/50 - 0s - loss: 9.2312 - acc: 0.8075 - val_loss: 0.3553 - val_acc: 0.8700\n",
      "Epoch 30/150\n",
      "50/50 - 0s - loss: 7.9972 - acc: 0.8037 - val_loss: 0.4677 - val_acc: 0.8700\n",
      "Epoch 31/150\n",
      "50/50 - 0s - loss: 6.5690 - acc: 0.8050 - val_loss: 0.3367 - val_acc: 0.8700\n",
      "Epoch 32/150\n",
      "50/50 - 0s - loss: 8.1307 - acc: 0.8006 - val_loss: 0.3434 - val_acc: 0.8700\n",
      "Epoch 33/150\n",
      "50/50 - 0s - loss: 5.0113 - acc: 0.8150 - val_loss: 0.4248 - val_acc: 0.8700\n",
      "Epoch 34/150\n",
      "50/50 - 0s - loss: 4.7494 - acc: 0.8219 - val_loss: 0.3437 - val_acc: 0.8700\n",
      "Epoch 35/150\n",
      "50/50 - 0s - loss: 4.3052 - acc: 0.8263 - val_loss: 0.3415 - val_acc: 0.8700\n",
      "Epoch 36/150\n",
      "50/50 - 0s - loss: 3.2823 - acc: 0.8319 - val_loss: 0.3637 - val_acc: 0.8700\n",
      "Epoch 37/150\n",
      "50/50 - 0s - loss: 3.8517 - acc: 0.8269 - val_loss: 0.3698 - val_acc: 0.8700\n",
      "Epoch 38/150\n",
      "50/50 - 0s - loss: 2.7928 - acc: 0.8300 - val_loss: 0.3537 - val_acc: 0.8700\n",
      "Epoch 39/150\n",
      "50/50 - 0s - loss: 2.1402 - acc: 0.8425 - val_loss: 0.3718 - val_acc: 0.8700\n",
      "Epoch 40/150\n",
      "50/50 - 0s - loss: 1.9302 - acc: 0.8325 - val_loss: 0.3273 - val_acc: 0.8700\n",
      "Epoch 41/150\n",
      "50/50 - 0s - loss: 1.5661 - acc: 0.8325 - val_loss: 0.3530 - val_acc: 0.8700\n",
      "Epoch 42/150\n",
      "50/50 - 0s - loss: 1.5131 - acc: 0.8419 - val_loss: 0.3096 - val_acc: 0.8700\n",
      "Epoch 43/150\n",
      "50/50 - 0s - loss: 1.2736 - acc: 0.8419 - val_loss: 0.3087 - val_acc: 0.8700\n",
      "Epoch 44/150\n",
      "50/50 - 0s - loss: 1.1914 - acc: 0.8344 - val_loss: 0.3157 - val_acc: 0.8700\n",
      "Epoch 45/150\n",
      "50/50 - 0s - loss: 0.9821 - acc: 0.8487 - val_loss: 0.3182 - val_acc: 0.8700\n",
      "Epoch 46/150\n",
      "50/50 - 0s - loss: 1.0370 - acc: 0.8419 - val_loss: 0.3079 - val_acc: 0.8700\n",
      "Epoch 47/150\n",
      "50/50 - 0s - loss: 0.7758 - acc: 0.8444 - val_loss: 0.2930 - val_acc: 0.8700\n",
      "Epoch 48/150\n",
      "50/50 - 0s - loss: 0.8267 - acc: 0.8438 - val_loss: 0.2946 - val_acc: 0.8700\n",
      "Epoch 49/150\n",
      "50/50 - 0s - loss: 0.7210 - acc: 0.8450 - val_loss: 0.2789 - val_acc: 0.8700\n",
      "Epoch 50/150\n",
      "50/50 - 0s - loss: 0.6743 - acc: 0.8431 - val_loss: 0.2773 - val_acc: 0.8700\n",
      "Epoch 51/150\n",
      "50/50 - 0s - loss: 0.5444 - acc: 0.8450 - val_loss: 0.2727 - val_acc: 0.8700\n",
      "Epoch 52/150\n",
      "50/50 - 0s - loss: 0.4747 - acc: 0.8450 - val_loss: 0.2740 - val_acc: 0.8700\n",
      "Epoch 53/150\n",
      "50/50 - 0s - loss: 0.5750 - acc: 0.8456 - val_loss: 0.2725 - val_acc: 0.8700\n",
      "Epoch 54/150\n",
      "50/50 - 0s - loss: 0.4012 - acc: 0.8481 - val_loss: 0.2714 - val_acc: 0.8700\n",
      "Epoch 55/150\n",
      "50/50 - 0s - loss: 0.4508 - acc: 0.8438 - val_loss: 0.2688 - val_acc: 0.8700\n",
      "Epoch 56/150\n",
      "50/50 - 0s - loss: 0.4631 - acc: 0.8475 - val_loss: 0.2666 - val_acc: 0.8700\n",
      "Epoch 57/150\n",
      "50/50 - 0s - loss: 0.3129 - acc: 0.8525 - val_loss: 0.2655 - val_acc: 0.8700\n",
      "Epoch 58/150\n",
      "50/50 - 0s - loss: 0.3251 - acc: 0.8512 - val_loss: 0.2644 - val_acc: 0.8700\n",
      "Epoch 59/150\n",
      "50/50 - 0s - loss: 0.3747 - acc: 0.8519 - val_loss: 0.2643 - val_acc: 0.8700\n",
      "Epoch 60/150\n",
      "50/50 - 0s - loss: 0.3429 - acc: 0.8462 - val_loss: 0.2638 - val_acc: 0.8700\n",
      "Epoch 61/150\n",
      "50/50 - 0s - loss: 0.4440 - acc: 0.8487 - val_loss: 0.2622 - val_acc: 0.8700\n",
      "Epoch 62/150\n",
      "50/50 - 0s - loss: 0.3112 - acc: 0.8525 - val_loss: 0.2623 - val_acc: 0.8700\n",
      "Epoch 63/150\n",
      "50/50 - 0s - loss: 0.3382 - acc: 0.8500 - val_loss: 0.2624 - val_acc: 0.8700\n",
      "Epoch 64/150\n",
      "50/50 - 0s - loss: 0.2967 - acc: 0.8531 - val_loss: 0.2617 - val_acc: 0.8700\n",
      "Epoch 65/150\n",
      "50/50 - 0s - loss: 0.2966 - acc: 0.8519 - val_loss: 0.2611 - val_acc: 0.8700\n",
      "Epoch 66/150\n",
      "50/50 - 0s - loss: 0.3359 - acc: 0.8531 - val_loss: 0.2604 - val_acc: 0.8700\n",
      "Epoch 67/150\n",
      "50/50 - 0s - loss: 0.3129 - acc: 0.8537 - val_loss: 0.2604 - val_acc: 0.8700\n",
      "Epoch 68/150\n",
      "50/50 - 0s - loss: 0.4472 - acc: 0.8519 - val_loss: 0.2589 - val_acc: 0.8700\n",
      "Epoch 69/150\n",
      "50/50 - 0s - loss: 0.3050 - acc: 0.8531 - val_loss: 0.2589 - val_acc: 0.8700\n",
      "Epoch 70/150\n",
      "50/50 - 0s - loss: 0.3902 - acc: 0.8512 - val_loss: 0.2578 - val_acc: 0.8700\n",
      "Epoch 71/150\n",
      "50/50 - 0s - loss: 0.3397 - acc: 0.8506 - val_loss: 0.2575 - val_acc: 0.8700\n",
      "Epoch 72/150\n",
      "50/50 - 0s - loss: 0.3953 - acc: 0.8487 - val_loss: 0.2577 - val_acc: 0.8700\n",
      "Epoch 73/150\n",
      "50/50 - 0s - loss: 0.2907 - acc: 0.8550 - val_loss: 0.2571 - val_acc: 0.8700\n",
      "Epoch 74/150\n",
      "50/50 - 0s - loss: 0.3151 - acc: 0.8537 - val_loss: 0.2564 - val_acc: 0.8700\n",
      "Epoch 75/150\n",
      "50/50 - 0s - loss: 0.3213 - acc: 0.8537 - val_loss: 0.2572 - val_acc: 0.8700\n",
      "Epoch 76/150\n",
      "50/50 - 0s - loss: 0.3753 - acc: 0.8512 - val_loss: 0.2554 - val_acc: 0.8700\n",
      "Epoch 77/150\n",
      "50/50 - 0s - loss: 0.2976 - acc: 0.8531 - val_loss: 0.2557 - val_acc: 0.8700\n",
      "Epoch 78/150\n",
      "50/50 - 0s - loss: 0.2857 - acc: 0.8550 - val_loss: 0.2564 - val_acc: 0.8700\n",
      "Epoch 79/150\n",
      "50/50 - 0s - loss: 0.3263 - acc: 0.8525 - val_loss: 0.2560 - val_acc: 0.8700\n",
      "Epoch 80/150\n",
      "50/50 - 0s - loss: 0.3006 - acc: 0.8550 - val_loss: 0.2550 - val_acc: 0.8700\n",
      "Epoch 81/150\n",
      "50/50 - 0s - loss: 0.3140 - acc: 0.8512 - val_loss: 0.2546 - val_acc: 0.8700\n",
      "Epoch 82/150\n",
      "50/50 - 0s - loss: 0.3324 - acc: 0.8525 - val_loss: 0.2567 - val_acc: 0.8700\n",
      "Epoch 83/150\n",
      "50/50 - 0s - loss: 0.3087 - acc: 0.8537 - val_loss: 0.2584 - val_acc: 0.8700\n",
      "Epoch 84/150\n",
      "50/50 - 0s - loss: 0.3220 - acc: 0.8525 - val_loss: 0.2576 - val_acc: 0.8700\n",
      "Epoch 85/150\n",
      "50/50 - 0s - loss: 0.3093 - acc: 0.8531 - val_loss: 0.2562 - val_acc: 0.8700\n",
      "Epoch 86/150\n",
      "50/50 - 0s - loss: 0.2926 - acc: 0.8544 - val_loss: 0.2558 - val_acc: 0.8700\n",
      "Epoch 87/150\n",
      "50/50 - 0s - loss: 0.3428 - acc: 0.8537 - val_loss: 0.2565 - val_acc: 0.8700\n",
      "Epoch 88/150\n",
      "50/50 - 0s - loss: 0.3097 - acc: 0.8550 - val_loss: 0.2547 - val_acc: 0.8700\n",
      "Epoch 89/150\n",
      "50/50 - 0s - loss: 0.3233 - acc: 0.8531 - val_loss: 0.2548 - val_acc: 0.8700\n",
      "Epoch 90/150\n",
      "50/50 - 0s - loss: 0.2926 - acc: 0.8537 - val_loss: 0.2540 - val_acc: 0.8700\n",
      "Epoch 91/150\n",
      "50/50 - 0s - loss: 0.3006 - acc: 0.8544 - val_loss: 0.2525 - val_acc: 0.8700\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 92/150\n",
      "50/50 - 0s - loss: 0.3247 - acc: 0.8519 - val_loss: 0.2522 - val_acc: 0.8700\n",
      "Epoch 93/150\n",
      "50/50 - 0s - loss: 0.3065 - acc: 0.8531 - val_loss: 0.2528 - val_acc: 0.8700\n",
      "Epoch 94/150\n",
      "50/50 - 0s - loss: 0.2930 - acc: 0.8544 - val_loss: 0.2528 - val_acc: 0.8700\n",
      "Epoch 95/150\n",
      "50/50 - 0s - loss: 0.3710 - acc: 0.8531 - val_loss: 0.2528 - val_acc: 0.8700\n",
      "Epoch 96/150\n",
      "50/50 - 0s - loss: 0.3559 - acc: 0.8525 - val_loss: 0.2515 - val_acc: 0.8700\n",
      "Epoch 97/150\n",
      "50/50 - 0s - loss: 0.2936 - acc: 0.8550 - val_loss: 0.2533 - val_acc: 0.8700\n",
      "Epoch 98/150\n",
      "50/50 - 0s - loss: 0.2951 - acc: 0.8544 - val_loss: 0.2531 - val_acc: 0.8700\n",
      "Epoch 99/150\n",
      "50/50 - 0s - loss: 0.2943 - acc: 0.8550 - val_loss: 0.2529 - val_acc: 0.8700\n",
      "Epoch 100/150\n",
      "50/50 - 0s - loss: 0.3221 - acc: 0.8550 - val_loss: 0.2528 - val_acc: 0.8700\n",
      "Epoch 101/150\n",
      "50/50 - 0s - loss: 0.3020 - acc: 0.8550 - val_loss: 0.2521 - val_acc: 0.8700\n",
      "Epoch 102/150\n",
      "50/50 - 0s - loss: 0.2820 - acc: 0.8550 - val_loss: 0.2552 - val_acc: 0.8700\n",
      "Epoch 103/150\n",
      "50/50 - 0s - loss: 0.2972 - acc: 0.8544 - val_loss: 0.2506 - val_acc: 0.8700\n",
      "Epoch 104/150\n",
      "50/50 - 0s - loss: 0.2807 - acc: 0.8550 - val_loss: 0.2522 - val_acc: 0.8700\n",
      "Epoch 105/150\n",
      "50/50 - 0s - loss: 0.3534 - acc: 0.8537 - val_loss: 0.2523 - val_acc: 0.8700\n",
      "Epoch 106/150\n",
      "50/50 - 0s - loss: 0.2961 - acc: 0.8537 - val_loss: 0.2523 - val_acc: 0.8700\n",
      "Epoch 107/150\n",
      "50/50 - 0s - loss: 0.2855 - acc: 0.8556 - val_loss: 0.2509 - val_acc: 0.8700\n",
      "Epoch 108/150\n",
      "50/50 - 0s - loss: 0.2807 - acc: 0.8556 - val_loss: 0.2521 - val_acc: 0.8700\n",
      "Epoch 109/150\n",
      "50/50 - 0s - loss: 0.2856 - acc: 0.8550 - val_loss: 0.2502 - val_acc: 0.8700\n",
      "Epoch 110/150\n",
      "50/50 - 0s - loss: 0.2806 - acc: 0.8556 - val_loss: 0.2523 - val_acc: 0.8700\n",
      "Epoch 111/150\n",
      "50/50 - 0s - loss: 0.2926 - acc: 0.8531 - val_loss: 0.2506 - val_acc: 0.8700\n",
      "Epoch 112/150\n",
      "50/50 - 0s - loss: 0.3147 - acc: 0.8550 - val_loss: 0.2502 - val_acc: 0.8700\n",
      "Epoch 113/150\n",
      "50/50 - 0s - loss: 0.3290 - acc: 0.8537 - val_loss: 0.2496 - val_acc: 0.8700\n",
      "Epoch 114/150\n",
      "50/50 - 0s - loss: 0.2887 - acc: 0.8550 - val_loss: 0.2499 - val_acc: 0.8700\n",
      "Epoch 115/150\n",
      "50/50 - 0s - loss: 0.2817 - acc: 0.8556 - val_loss: 0.2499 - val_acc: 0.8700\n",
      "Epoch 116/150\n",
      "50/50 - 0s - loss: 0.3132 - acc: 0.8544 - val_loss: 0.2516 - val_acc: 0.8700\n",
      "Epoch 117/150\n",
      "50/50 - 0s - loss: 0.3039 - acc: 0.8544 - val_loss: 0.2533 - val_acc: 0.8700\n",
      "Epoch 118/150\n",
      "50/50 - 0s - loss: 0.2878 - acc: 0.8556 - val_loss: 0.2553 - val_acc: 0.8700\n",
      "Epoch 119/150\n",
      "50/50 - 0s - loss: 0.2888 - acc: 0.8556 - val_loss: 0.2521 - val_acc: 0.8700\n",
      "Epoch 120/150\n",
      "50/50 - 0s - loss: 0.2870 - acc: 0.8544 - val_loss: 0.2501 - val_acc: 0.8700\n",
      "Epoch 121/150\n",
      "50/50 - 0s - loss: 0.3109 - acc: 0.8544 - val_loss: 0.2506 - val_acc: 0.8700\n",
      "Epoch 122/150\n",
      "50/50 - 0s - loss: 0.3005 - acc: 0.8544 - val_loss: 0.2495 - val_acc: 0.8700\n",
      "Epoch 123/150\n",
      "50/50 - 0s - loss: 0.2963 - acc: 0.8537 - val_loss: 0.2505 - val_acc: 0.8700\n",
      "Epoch 124/150\n",
      "50/50 - 0s - loss: 0.3060 - acc: 0.8537 - val_loss: 0.2532 - val_acc: 0.8700\n",
      "Epoch 125/150\n",
      "50/50 - 0s - loss: 0.2975 - acc: 0.8550 - val_loss: 0.2525 - val_acc: 0.8700\n",
      "Epoch 126/150\n",
      "50/50 - 0s - loss: 0.2888 - acc: 0.8550 - val_loss: 0.2499 - val_acc: 0.8700\n",
      "Epoch 127/150\n",
      "50/50 - 0s - loss: 0.2861 - acc: 0.8550 - val_loss: 0.2502 - val_acc: 0.8700\n",
      "Epoch 128/150\n",
      "50/50 - 0s - loss: 0.2955 - acc: 0.8556 - val_loss: 0.2498 - val_acc: 0.8700\n",
      "Epoch 129/150\n",
      "50/50 - 0s - loss: 0.3045 - acc: 0.8550 - val_loss: 0.2510 - val_acc: 0.8700\n",
      "Epoch 130/150\n",
      "50/50 - 0s - loss: 0.2848 - acc: 0.8550 - val_loss: 0.2498 - val_acc: 0.8700\n",
      "Epoch 131/150\n",
      "50/50 - 0s - loss: 0.2954 - acc: 0.8544 - val_loss: 0.2496 - val_acc: 0.8700\n",
      "Epoch 132/150\n",
      "50/50 - 0s - loss: 0.3189 - acc: 0.8544 - val_loss: 0.2499 - val_acc: 0.8700\n",
      "Epoch 133/150\n",
      "50/50 - 0s - loss: 0.2824 - acc: 0.8550 - val_loss: 0.2513 - val_acc: 0.8700\n",
      "Epoch 134/150\n",
      "50/50 - 0s - loss: 0.3097 - acc: 0.8550 - val_loss: 0.2501 - val_acc: 0.8700\n",
      "Epoch 135/150\n",
      "50/50 - 0s - loss: 0.2868 - acc: 0.8550 - val_loss: 0.2492 - val_acc: 0.8700\n",
      "Epoch 136/150\n",
      "50/50 - 0s - loss: 0.2990 - acc: 0.8544 - val_loss: 0.2492 - val_acc: 0.8700\n",
      "Epoch 137/150\n",
      "50/50 - 0s - loss: 0.2970 - acc: 0.8550 - val_loss: 0.2493 - val_acc: 0.8700\n",
      "Epoch 138/150\n",
      "50/50 - 0s - loss: 0.2791 - acc: 0.8556 - val_loss: 0.2500 - val_acc: 0.8700\n",
      "Epoch 139/150\n",
      "50/50 - 0s - loss: 0.2923 - acc: 0.8544 - val_loss: 0.2539 - val_acc: 0.8700\n",
      "Epoch 140/150\n",
      "50/50 - 0s - loss: 0.2856 - acc: 0.8556 - val_loss: 0.2494 - val_acc: 0.8700\n",
      "Epoch 141/150\n",
      "50/50 - 0s - loss: 0.2855 - acc: 0.8556 - val_loss: 0.2489 - val_acc: 0.8700\n",
      "Epoch 142/150\n",
      "50/50 - 0s - loss: 0.2831 - acc: 0.8556 - val_loss: 0.2498 - val_acc: 0.8700\n",
      "Epoch 143/150\n",
      "50/50 - 0s - loss: 0.2974 - acc: 0.8544 - val_loss: 0.2580 - val_acc: 0.8700\n",
      "Epoch 144/150\n",
      "50/50 - 0s - loss: 0.2823 - acc: 0.8556 - val_loss: 0.2501 - val_acc: 0.8700\n",
      "Epoch 145/150\n",
      "50/50 - 0s - loss: 0.2831 - acc: 0.8556 - val_loss: 0.2501 - val_acc: 0.8700\n",
      "Epoch 146/150\n",
      "50/50 - 0s - loss: 0.2902 - acc: 0.8550 - val_loss: 0.2497 - val_acc: 0.8700\n",
      "Epoch 147/150\n",
      "50/50 - 0s - loss: 0.3206 - acc: 0.8544 - val_loss: 0.2490 - val_acc: 0.8700\n",
      "Epoch 148/150\n",
      "50/50 - 0s - loss: 0.2968 - acc: 0.8537 - val_loss: 0.2578 - val_acc: 0.8700\n",
      "Epoch 149/150\n",
      "50/50 - 0s - loss: 0.3133 - acc: 0.8525 - val_loss: 0.2484 - val_acc: 0.8700\n",
      "Epoch 150/150\n",
      "50/50 - 0s - loss: 0.2831 - acc: 0.8556 - val_loss: 0.2582 - val_acc: 0.8700\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.python.keras import Sequential\n",
    "from tensorflow.python.keras.layers import Dense,Dropout\n",
    "\n",
    "model=Sequential([Dense(3,activation='relu'),\n",
    "                 Dropout(.3),\n",
    "                 Dense(16,activation='relu'),\n",
    "                 Dropout(.3),\n",
    "\n",
    "                 Dense(32,activation='relu'),\n",
    "                 Dropout(.3),\n",
    "\n",
    "                 Dense(1,activation='sigmoid'),\n",
    "                 \n",
    "                 ])\n",
    "model.compile(optimizer='adam', loss = 'binary_crossentropy',metrics=['acc'])\n",
    "history=model.fit(X_wc_train, y_train,validation_data=(X_wc_test,y_test), batch_size = 32, epochs = 150,verbose=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[348   0]\n",
      " [ 52   0]]\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(X_wc_test)\n",
    "y_pred = (y_pred > 0.5)\n",
    "\n",
    "# Making the Confusion Matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print(cm)\n",
    "#val_acc does not increase "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "income    0\n",
       "age       0\n",
       "loan      0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "blank=X[X['age']==' '].count()\n",
    "blank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#use elbow method to determine the best number of clusters\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.cluster import KMeans\n",
    "wcss = []\n",
    "for i in range(1, 11):\n",
    "    kmeans = KMeans(n_clusters = i, init = 'k-means++', random_state = 0)\n",
    "    kmeans.fit(X)\n",
    "    wcss.append(kmeans.inertia_)\n",
    "plt.plot(range(1, 11), wcss)\n",
    "plt.title('The Elbow Method')\n",
    "plt.xlabel('Number of clusters')\n",
    "plt.ylabel('WCSS')\n",
    "plt.show()\n",
    "#the result shows that the best number of clusters is 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 1, 2, ..., 0, 0, 2])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#run kmeans algo on the dataset\n",
    "kmeans = KMeans(n_clusters = 3, init = 'k-means++', random_state = 0)\n",
    "y_kmeans = kmeans.fit_predict(X)\n",
    "y_kmeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>income</th>\n",
       "      <th>age</th>\n",
       "      <th>loan</th>\n",
       "      <th>cluster</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>66155.925095</td>\n",
       "      <td>59.017015</td>\n",
       "      <td>8106.532131</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>34415.153966</td>\n",
       "      <td>48.117153</td>\n",
       "      <td>6564.745018</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>57317.170063</td>\n",
       "      <td>63.108049</td>\n",
       "      <td>8020.953296</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>42709.534201</td>\n",
       "      <td>45.751972</td>\n",
       "      <td>6103.642260</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>66952.688845</td>\n",
       "      <td>18.584336</td>\n",
       "      <td>8770.099235</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1995</th>\n",
       "      <td>59221.044874</td>\n",
       "      <td>48.518179</td>\n",
       "      <td>1926.729397</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1996</th>\n",
       "      <td>69516.127573</td>\n",
       "      <td>23.162104</td>\n",
       "      <td>3503.176156</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1997</th>\n",
       "      <td>44311.449262</td>\n",
       "      <td>28.017167</td>\n",
       "      <td>5522.786693</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1998</th>\n",
       "      <td>43756.056605</td>\n",
       "      <td>63.971796</td>\n",
       "      <td>1622.722598</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1999</th>\n",
       "      <td>69436.579552</td>\n",
       "      <td>56.152617</td>\n",
       "      <td>7378.833599</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2000 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            income        age         loan  cluster\n",
       "0     66155.925095  59.017015  8106.532131        2\n",
       "1     34415.153966  48.117153  6564.745018        1\n",
       "2     57317.170063  63.108049  8020.953296        2\n",
       "3     42709.534201  45.751972  6103.642260        0\n",
       "4     66952.688845  18.584336  8770.099235        2\n",
       "...            ...        ...          ...      ...\n",
       "1995  59221.044874  48.518179  1926.729397        2\n",
       "1996  69516.127573  23.162104  3503.176156        2\n",
       "1997  44311.449262  28.017167  5522.786693        0\n",
       "1998  43756.056605  63.971796  1622.722598        0\n",
       "1999  69436.579552  56.152617  7378.833599        2\n",
       "\n",
       "[2000 rows x 4 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#add the result as a new column to the dataset\n",
    "arr=y_kmeans\n",
    "X['cluster'] = arr.tolist()\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting the dataset into the Training set and Test set\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 0)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#normalize the trainig data \n",
    "from sklearn.preprocessing import StandardScaler \n",
    "sc=StandardScaler()\n",
    "X_train=sc.fit_transform(X_train)\n",
    "X_test=sc.fit_transform(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[339   9]\n",
      " [  7  45]]\n"
     ]
    }
   ],
   "source": [
    "#excute LR model \n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "model = LogisticRegression()\n",
    "\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "y_pred=model.predict(X_test)\n",
    "# Making the Confusion Matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print(cm)\n",
    "#accuarcy after adding cluster number is 95.7%\n",
    "#recall is 97.6% (the most important metric because ofthe unblance in data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "50/50 - 1s - loss: 0.5591 - acc: 0.8119 - val_loss: 0.4573 - val_acc: 0.8700\n",
      "Epoch 2/150\n",
      "50/50 - 0s - loss: 0.4497 - acc: 0.8531 - val_loss: 0.3866 - val_acc: 0.8700\n",
      "Epoch 3/150\n",
      "50/50 - 0s - loss: 0.4078 - acc: 0.8556 - val_loss: 0.3550 - val_acc: 0.8700\n",
      "Epoch 4/150\n",
      "50/50 - 0s - loss: 0.3842 - acc: 0.8556 - val_loss: 0.3361 - val_acc: 0.8700\n",
      "Epoch 5/150\n",
      "50/50 - 0s - loss: 0.3652 - acc: 0.8550 - val_loss: 0.3144 - val_acc: 0.8700\n",
      "Epoch 6/150\n",
      "50/50 - 0s - loss: 0.3498 - acc: 0.8556 - val_loss: 0.2950 - val_acc: 0.8700\n",
      "Epoch 7/150\n",
      "50/50 - 0s - loss: 0.3329 - acc: 0.8569 - val_loss: 0.2725 - val_acc: 0.8700\n",
      "Epoch 8/150\n",
      "50/50 - 0s - loss: 0.3247 - acc: 0.8550 - val_loss: 0.2507 - val_acc: 0.8700\n",
      "Epoch 9/150\n",
      "50/50 - 0s - loss: 0.3079 - acc: 0.8625 - val_loss: 0.2267 - val_acc: 0.8700\n",
      "Epoch 10/150\n",
      "50/50 - 0s - loss: 0.2938 - acc: 0.8650 - val_loss: 0.2062 - val_acc: 0.8875\n",
      "Epoch 11/150\n",
      "50/50 - 0s - loss: 0.2819 - acc: 0.8662 - val_loss: 0.1910 - val_acc: 0.8950\n",
      "Epoch 12/150\n",
      "50/50 - 0s - loss: 0.2643 - acc: 0.8763 - val_loss: 0.1709 - val_acc: 0.9225\n",
      "Epoch 13/150\n",
      "50/50 - 0s - loss: 0.2484 - acc: 0.8831 - val_loss: 0.1545 - val_acc: 0.9350\n",
      "Epoch 14/150\n",
      "50/50 - 0s - loss: 0.2575 - acc: 0.8788 - val_loss: 0.1477 - val_acc: 0.9375\n",
      "Epoch 15/150\n",
      "50/50 - 0s - loss: 0.2471 - acc: 0.8913 - val_loss: 0.1352 - val_acc: 0.9400\n",
      "Epoch 16/150\n",
      "50/50 - 0s - loss: 0.2316 - acc: 0.8950 - val_loss: 0.1269 - val_acc: 0.9425\n",
      "Epoch 17/150\n",
      "50/50 - 0s - loss: 0.2235 - acc: 0.8981 - val_loss: 0.1183 - val_acc: 0.9550\n",
      "Epoch 18/150\n",
      "50/50 - 0s - loss: 0.2112 - acc: 0.9156 - val_loss: 0.1080 - val_acc: 0.9625\n",
      "Epoch 19/150\n",
      "50/50 - 0s - loss: 0.2214 - acc: 0.9069 - val_loss: 0.1039 - val_acc: 0.9650\n",
      "Epoch 20/150\n",
      "50/50 - 0s - loss: 0.2118 - acc: 0.9112 - val_loss: 0.1036 - val_acc: 0.9625\n",
      "Epoch 21/150\n",
      "50/50 - 0s - loss: 0.1978 - acc: 0.9187 - val_loss: 0.0914 - val_acc: 0.9775\n",
      "Epoch 22/150\n",
      "50/50 - 0s - loss: 0.1937 - acc: 0.9187 - val_loss: 0.0855 - val_acc: 0.9800\n",
      "Epoch 23/150\n",
      "50/50 - 0s - loss: 0.1944 - acc: 0.9162 - val_loss: 0.0855 - val_acc: 0.9725\n",
      "Epoch 24/150\n",
      "50/50 - 0s - loss: 0.1922 - acc: 0.9131 - val_loss: 0.0814 - val_acc: 0.9800\n",
      "Epoch 25/150\n",
      "50/50 - 0s - loss: 0.1849 - acc: 0.9250 - val_loss: 0.0817 - val_acc: 0.9725\n",
      "Epoch 26/150\n",
      "50/50 - 0s - loss: 0.1785 - acc: 0.9262 - val_loss: 0.0721 - val_acc: 0.9850\n",
      "Epoch 27/150\n",
      "50/50 - 0s - loss: 0.1744 - acc: 0.9231 - val_loss: 0.0673 - val_acc: 0.9825\n",
      "Epoch 28/150\n",
      "50/50 - 0s - loss: 0.1832 - acc: 0.9250 - val_loss: 0.0710 - val_acc: 0.9800\n",
      "Epoch 29/150\n",
      "50/50 - 0s - loss: 0.1806 - acc: 0.9194 - val_loss: 0.0691 - val_acc: 0.9800\n",
      "Epoch 30/150\n",
      "50/50 - 0s - loss: 0.1581 - acc: 0.9312 - val_loss: 0.0753 - val_acc: 0.9725\n",
      "Epoch 31/150\n",
      "50/50 - 0s - loss: 0.1627 - acc: 0.9275 - val_loss: 0.0665 - val_acc: 0.9800\n",
      "Epoch 32/150\n",
      "50/50 - 0s - loss: 0.1741 - acc: 0.9237 - val_loss: 0.0671 - val_acc: 0.9775\n",
      "Epoch 33/150\n",
      "50/50 - 0s - loss: 0.1492 - acc: 0.9406 - val_loss: 0.0606 - val_acc: 0.9750\n",
      "Epoch 34/150\n",
      "50/50 - 0s - loss: 0.1577 - acc: 0.9319 - val_loss: 0.0619 - val_acc: 0.9800\n",
      "Epoch 35/150\n",
      "50/50 - 0s - loss: 0.1568 - acc: 0.9306 - val_loss: 0.0634 - val_acc: 0.9775\n",
      "Epoch 36/150\n",
      "50/50 - 0s - loss: 0.1528 - acc: 0.9319 - val_loss: 0.0534 - val_acc: 0.9825\n",
      "Epoch 37/150\n",
      "50/50 - 0s - loss: 0.1469 - acc: 0.9362 - val_loss: 0.0526 - val_acc: 0.9825\n",
      "Epoch 38/150\n",
      "50/50 - 0s - loss: 0.1568 - acc: 0.9319 - val_loss: 0.0633 - val_acc: 0.9800\n",
      "Epoch 39/150\n",
      "50/50 - 0s - loss: 0.1573 - acc: 0.9306 - val_loss: 0.0533 - val_acc: 0.9800\n",
      "Epoch 40/150\n",
      "50/50 - 0s - loss: 0.1476 - acc: 0.9306 - val_loss: 0.0549 - val_acc: 0.9825\n",
      "Epoch 41/150\n",
      "50/50 - 0s - loss: 0.1455 - acc: 0.9375 - val_loss: 0.0516 - val_acc: 0.9825\n",
      "Epoch 42/150\n",
      "50/50 - 0s - loss: 0.1547 - acc: 0.9275 - val_loss: 0.0523 - val_acc: 0.9800\n",
      "Epoch 43/150\n",
      "50/50 - 0s - loss: 0.1562 - acc: 0.9300 - val_loss: 0.0544 - val_acc: 0.9825\n",
      "Epoch 44/150\n",
      "50/50 - 0s - loss: 0.1433 - acc: 0.9344 - val_loss: 0.0559 - val_acc: 0.9825\n",
      "Epoch 45/150\n",
      "50/50 - 0s - loss: 0.1466 - acc: 0.9388 - val_loss: 0.0562 - val_acc: 0.9850\n",
      "Epoch 46/150\n",
      "50/50 - 0s - loss: 0.1454 - acc: 0.9287 - val_loss: 0.0543 - val_acc: 0.9825\n",
      "Epoch 47/150\n",
      "50/50 - 0s - loss: 0.1450 - acc: 0.9356 - val_loss: 0.0552 - val_acc: 0.9800\n",
      "Epoch 48/150\n",
      "50/50 - 0s - loss: 0.1442 - acc: 0.9344 - val_loss: 0.0572 - val_acc: 0.9750\n",
      "Epoch 49/150\n",
      "50/50 - 0s - loss: 0.1298 - acc: 0.9444 - val_loss: 0.0468 - val_acc: 0.9825\n",
      "Epoch 50/150\n",
      "50/50 - 0s - loss: 0.1350 - acc: 0.9419 - val_loss: 0.0522 - val_acc: 0.9825\n",
      "Epoch 51/150\n",
      "50/50 - 0s - loss: 0.1404 - acc: 0.9319 - val_loss: 0.0506 - val_acc: 0.9850\n",
      "Epoch 52/150\n",
      "50/50 - 0s - loss: 0.1450 - acc: 0.9394 - val_loss: 0.0523 - val_acc: 0.9850\n",
      "Epoch 53/150\n",
      "50/50 - 0s - loss: 0.1255 - acc: 0.9488 - val_loss: 0.0507 - val_acc: 0.9800\n",
      "Epoch 54/150\n",
      "50/50 - 0s - loss: 0.1507 - acc: 0.9350 - val_loss: 0.0526 - val_acc: 0.9875\n",
      "Epoch 55/150\n",
      "50/50 - 0s - loss: 0.1388 - acc: 0.9381 - val_loss: 0.0516 - val_acc: 0.9800\n",
      "Epoch 56/150\n",
      "50/50 - 0s - loss: 0.1498 - acc: 0.9331 - val_loss: 0.0502 - val_acc: 0.9775\n",
      "Epoch 57/150\n",
      "50/50 - 0s - loss: 0.1409 - acc: 0.9381 - val_loss: 0.0516 - val_acc: 0.9750\n",
      "Epoch 58/150\n",
      "50/50 - 0s - loss: 0.1331 - acc: 0.9381 - val_loss: 0.0438 - val_acc: 0.9850\n",
      "Epoch 59/150\n",
      "50/50 - 0s - loss: 0.1370 - acc: 0.9400 - val_loss: 0.0420 - val_acc: 0.9850\n",
      "Epoch 60/150\n",
      "50/50 - 0s - loss: 0.1364 - acc: 0.9350 - val_loss: 0.0426 - val_acc: 0.9850\n",
      "Epoch 61/150\n",
      "50/50 - 0s - loss: 0.1234 - acc: 0.9438 - val_loss: 0.0445 - val_acc: 0.9900\n",
      "Epoch 62/150\n",
      "50/50 - 0s - loss: 0.1258 - acc: 0.9450 - val_loss: 0.0413 - val_acc: 0.9900\n",
      "Epoch 63/150\n",
      "50/50 - 0s - loss: 0.1401 - acc: 0.9256 - val_loss: 0.0416 - val_acc: 0.9825\n",
      "Epoch 64/150\n",
      "50/50 - 0s - loss: 0.1364 - acc: 0.9337 - val_loss: 0.0451 - val_acc: 0.9900\n",
      "Epoch 65/150\n",
      "50/50 - 0s - loss: 0.1339 - acc: 0.9362 - val_loss: 0.0426 - val_acc: 0.9900\n",
      "Epoch 66/150\n",
      "50/50 - 0s - loss: 0.1344 - acc: 0.9375 - val_loss: 0.0465 - val_acc: 0.9875\n",
      "Epoch 67/150\n",
      "50/50 - 0s - loss: 0.1405 - acc: 0.9287 - val_loss: 0.0414 - val_acc: 0.9850\n",
      "Epoch 68/150\n",
      "50/50 - 0s - loss: 0.1305 - acc: 0.9400 - val_loss: 0.0391 - val_acc: 0.9850\n",
      "Epoch 69/150\n",
      "50/50 - 0s - loss: 0.1357 - acc: 0.9369 - val_loss: 0.0516 - val_acc: 0.9825\n",
      "Epoch 70/150\n",
      "50/50 - 0s - loss: 0.1283 - acc: 0.9413 - val_loss: 0.0444 - val_acc: 0.9900\n",
      "Epoch 71/150\n",
      "50/50 - 0s - loss: 0.1294 - acc: 0.9463 - val_loss: 0.0498 - val_acc: 0.9850\n",
      "Epoch 72/150\n",
      "50/50 - 0s - loss: 0.1298 - acc: 0.9456 - val_loss: 0.0405 - val_acc: 0.9900\n",
      "Epoch 73/150\n",
      "50/50 - 0s - loss: 0.1263 - acc: 0.9400 - val_loss: 0.0362 - val_acc: 0.9850\n",
      "Epoch 74/150\n",
      "50/50 - 0s - loss: 0.1336 - acc: 0.9400 - val_loss: 0.0373 - val_acc: 0.9850\n",
      "Epoch 75/150\n",
      "50/50 - 0s - loss: 0.1273 - acc: 0.9400 - val_loss: 0.0408 - val_acc: 0.9900\n",
      "Epoch 76/150\n",
      "50/50 - 0s - loss: 0.1239 - acc: 0.9381 - val_loss: 0.0368 - val_acc: 0.9875\n",
      "Epoch 77/150\n",
      "50/50 - 0s - loss: 0.1251 - acc: 0.9400 - val_loss: 0.0424 - val_acc: 0.9900\n",
      "Epoch 78/150\n",
      "50/50 - 0s - loss: 0.1315 - acc: 0.9362 - val_loss: 0.0419 - val_acc: 0.9900\n",
      "Epoch 79/150\n",
      "50/50 - 0s - loss: 0.1294 - acc: 0.9350 - val_loss: 0.0406 - val_acc: 0.9875\n",
      "Epoch 80/150\n",
      "50/50 - 0s - loss: 0.1272 - acc: 0.9375 - val_loss: 0.0387 - val_acc: 0.9900\n",
      "Epoch 81/150\n",
      "50/50 - 0s - loss: 0.1241 - acc: 0.9444 - val_loss: 0.0318 - val_acc: 0.9900\n",
      "Epoch 82/150\n",
      "50/50 - 0s - loss: 0.1173 - acc: 0.9438 - val_loss: 0.0374 - val_acc: 0.9875\n",
      "Epoch 83/150\n",
      "50/50 - 0s - loss: 0.1177 - acc: 0.9481 - val_loss: 0.0438 - val_acc: 0.9875\n",
      "Epoch 84/150\n",
      "50/50 - 0s - loss: 0.1247 - acc: 0.9450 - val_loss: 0.0516 - val_acc: 0.9850\n",
      "Epoch 85/150\n",
      "50/50 - 0s - loss: 0.1262 - acc: 0.9450 - val_loss: 0.0344 - val_acc: 0.9900\n",
      "Epoch 86/150\n",
      "50/50 - 0s - loss: 0.1221 - acc: 0.9438 - val_loss: 0.0342 - val_acc: 0.9900\n",
      "Epoch 87/150\n",
      "50/50 - 0s - loss: 0.1260 - acc: 0.9388 - val_loss: 0.0362 - val_acc: 0.9900\n",
      "Epoch 88/150\n",
      "50/50 - 0s - loss: 0.1152 - acc: 0.9438 - val_loss: 0.0324 - val_acc: 0.9900\n",
      "Epoch 89/150\n",
      "50/50 - 0s - loss: 0.1074 - acc: 0.9494 - val_loss: 0.0337 - val_acc: 0.9875\n",
      "Epoch 90/150\n",
      "50/50 - 0s - loss: 0.1228 - acc: 0.9425 - val_loss: 0.0362 - val_acc: 0.9900\n",
      "Epoch 91/150\n",
      "50/50 - 0s - loss: 0.1248 - acc: 0.9419 - val_loss: 0.0318 - val_acc: 0.9900\n",
      "Epoch 92/150\n",
      "50/50 - 0s - loss: 0.1190 - acc: 0.9438 - val_loss: 0.0328 - val_acc: 0.9875\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 93/150\n",
      "50/50 - 0s - loss: 0.1177 - acc: 0.9413 - val_loss: 0.0338 - val_acc: 0.9900\n",
      "Epoch 94/150\n",
      "50/50 - 0s - loss: 0.1247 - acc: 0.9388 - val_loss: 0.0349 - val_acc: 0.9875\n",
      "Epoch 95/150\n",
      "50/50 - 0s - loss: 0.1060 - acc: 0.9500 - val_loss: 0.0316 - val_acc: 0.9900\n",
      "Epoch 96/150\n",
      "50/50 - 0s - loss: 0.1344 - acc: 0.9362 - val_loss: 0.0429 - val_acc: 0.9875\n",
      "Epoch 97/150\n",
      "50/50 - 0s - loss: 0.1270 - acc: 0.9400 - val_loss: 0.0351 - val_acc: 0.9900\n",
      "Epoch 98/150\n",
      "50/50 - 0s - loss: 0.1263 - acc: 0.9331 - val_loss: 0.0329 - val_acc: 0.9900\n",
      "Epoch 99/150\n",
      "50/50 - 0s - loss: 0.1230 - acc: 0.9406 - val_loss: 0.0370 - val_acc: 0.9875\n",
      "Epoch 100/150\n",
      "50/50 - 0s - loss: 0.1328 - acc: 0.9362 - val_loss: 0.0340 - val_acc: 0.9900\n",
      "Epoch 101/150\n",
      "50/50 - 0s - loss: 0.1116 - acc: 0.9506 - val_loss: 0.0390 - val_acc: 0.9900\n",
      "Epoch 102/150\n",
      "50/50 - 0s - loss: 0.1128 - acc: 0.9494 - val_loss: 0.0326 - val_acc: 0.9875\n",
      "Epoch 103/150\n",
      "50/50 - 0s - loss: 0.1319 - acc: 0.9406 - val_loss: 0.0318 - val_acc: 0.9850\n",
      "Epoch 104/150\n",
      "50/50 - 0s - loss: 0.1175 - acc: 0.9475 - val_loss: 0.0355 - val_acc: 0.9850\n",
      "Epoch 105/150\n",
      "50/50 - 0s - loss: 0.1305 - acc: 0.9369 - val_loss: 0.0398 - val_acc: 0.9900\n",
      "Epoch 106/150\n",
      "50/50 - 0s - loss: 0.1188 - acc: 0.9406 - val_loss: 0.0330 - val_acc: 0.9875\n",
      "Epoch 107/150\n",
      "50/50 - 0s - loss: 0.1251 - acc: 0.9431 - val_loss: 0.0421 - val_acc: 0.9900\n",
      "Epoch 108/150\n",
      "50/50 - 0s - loss: 0.1192 - acc: 0.9394 - val_loss: 0.0351 - val_acc: 0.9875\n",
      "Epoch 109/150\n",
      "50/50 - 0s - loss: 0.1136 - acc: 0.9456 - val_loss: 0.0302 - val_acc: 0.9900\n",
      "Epoch 110/150\n",
      "50/50 - 0s - loss: 0.1284 - acc: 0.9388 - val_loss: 0.0386 - val_acc: 0.9900\n",
      "Epoch 111/150\n",
      "50/50 - 0s - loss: 0.1215 - acc: 0.9419 - val_loss: 0.0390 - val_acc: 0.9850\n",
      "Epoch 112/150\n",
      "50/50 - 0s - loss: 0.1261 - acc: 0.9375 - val_loss: 0.0375 - val_acc: 0.9850\n",
      "Epoch 113/150\n",
      "50/50 - 0s - loss: 0.1312 - acc: 0.9362 - val_loss: 0.0400 - val_acc: 0.9875\n",
      "Epoch 114/150\n",
      "50/50 - 0s - loss: 0.1346 - acc: 0.9350 - val_loss: 0.0394 - val_acc: 0.9850\n",
      "Epoch 115/150\n",
      "50/50 - 0s - loss: 0.1207 - acc: 0.9475 - val_loss: 0.0347 - val_acc: 0.9900\n",
      "Epoch 116/150\n",
      "50/50 - 0s - loss: 0.1375 - acc: 0.9275 - val_loss: 0.0453 - val_acc: 0.9900\n",
      "Epoch 117/150\n",
      "50/50 - 0s - loss: 0.1172 - acc: 0.9419 - val_loss: 0.0351 - val_acc: 0.9850\n",
      "Epoch 118/150\n",
      "50/50 - 0s - loss: 0.1248 - acc: 0.9344 - val_loss: 0.0299 - val_acc: 0.9900\n",
      "Epoch 119/150\n",
      "50/50 - 0s - loss: 0.1187 - acc: 0.9413 - val_loss: 0.0310 - val_acc: 0.9900\n",
      "Epoch 120/150\n",
      "50/50 - 0s - loss: 0.1310 - acc: 0.9388 - val_loss: 0.0334 - val_acc: 0.9900\n",
      "Epoch 121/150\n",
      "50/50 - 0s - loss: 0.1351 - acc: 0.9362 - val_loss: 0.0393 - val_acc: 0.9875\n",
      "Epoch 122/150\n",
      "50/50 - 0s - loss: 0.1135 - acc: 0.9494 - val_loss: 0.0376 - val_acc: 0.9850\n",
      "Epoch 123/150\n",
      "50/50 - 0s - loss: 0.1345 - acc: 0.9319 - val_loss: 0.0387 - val_acc: 0.9875\n",
      "Epoch 124/150\n",
      "50/50 - 0s - loss: 0.1192 - acc: 0.9456 - val_loss: 0.0350 - val_acc: 0.9900\n",
      "Epoch 125/150\n",
      "50/50 - 0s - loss: 0.1308 - acc: 0.9400 - val_loss: 0.0422 - val_acc: 0.9875\n",
      "Epoch 126/150\n",
      "50/50 - 0s - loss: 0.1211 - acc: 0.9400 - val_loss: 0.0306 - val_acc: 0.9900\n",
      "Epoch 127/150\n",
      "50/50 - 0s - loss: 0.1188 - acc: 0.9381 - val_loss: 0.0272 - val_acc: 0.9925\n",
      "Epoch 128/150\n",
      "50/50 - 0s - loss: 0.1181 - acc: 0.9475 - val_loss: 0.0297 - val_acc: 0.9925\n",
      "Epoch 129/150\n",
      "50/50 - 0s - loss: 0.1140 - acc: 0.9444 - val_loss: 0.0306 - val_acc: 0.9900\n",
      "Epoch 130/150\n",
      "50/50 - 0s - loss: 0.1150 - acc: 0.9431 - val_loss: 0.0314 - val_acc: 0.9850\n",
      "Epoch 131/150\n",
      "50/50 - 0s - loss: 0.1220 - acc: 0.9381 - val_loss: 0.0354 - val_acc: 0.9875\n",
      "Epoch 132/150\n",
      "50/50 - 0s - loss: 0.1176 - acc: 0.9431 - val_loss: 0.0333 - val_acc: 0.9900\n",
      "Epoch 133/150\n",
      "50/50 - 0s - loss: 0.1233 - acc: 0.9406 - val_loss: 0.0337 - val_acc: 0.9900\n",
      "Epoch 134/150\n",
      "50/50 - 0s - loss: 0.1113 - acc: 0.9513 - val_loss: 0.0298 - val_acc: 0.9875\n",
      "Epoch 135/150\n",
      "50/50 - 0s - loss: 0.1243 - acc: 0.9375 - val_loss: 0.0321 - val_acc: 0.9850\n",
      "Epoch 136/150\n",
      "50/50 - 0s - loss: 0.1201 - acc: 0.9431 - val_loss: 0.0335 - val_acc: 0.9900\n",
      "Epoch 137/150\n",
      "50/50 - 0s - loss: 0.1256 - acc: 0.9356 - val_loss: 0.0322 - val_acc: 0.9900\n",
      "Epoch 138/150\n",
      "50/50 - 0s - loss: 0.1178 - acc: 0.9431 - val_loss: 0.0284 - val_acc: 0.9900\n",
      "Epoch 139/150\n",
      "50/50 - 0s - loss: 0.1088 - acc: 0.9463 - val_loss: 0.0262 - val_acc: 0.9925\n",
      "Epoch 140/150\n",
      "50/50 - 0s - loss: 0.1248 - acc: 0.9488 - val_loss: 0.0346 - val_acc: 0.9900\n",
      "Epoch 141/150\n",
      "50/50 - 0s - loss: 0.1170 - acc: 0.9438 - val_loss: 0.0303 - val_acc: 0.9875\n",
      "Epoch 142/150\n",
      "50/50 - 0s - loss: 0.1111 - acc: 0.9475 - val_loss: 0.0390 - val_acc: 0.9850\n",
      "Epoch 143/150\n",
      "50/50 - 0s - loss: 0.1140 - acc: 0.9469 - val_loss: 0.0331 - val_acc: 0.9875\n",
      "Epoch 144/150\n",
      "50/50 - 0s - loss: 0.1181 - acc: 0.9431 - val_loss: 0.0322 - val_acc: 0.9875\n",
      "Epoch 145/150\n",
      "50/50 - 0s - loss: 0.1218 - acc: 0.9394 - val_loss: 0.0348 - val_acc: 0.9900\n",
      "Epoch 146/150\n",
      "50/50 - 0s - loss: 0.1155 - acc: 0.9456 - val_loss: 0.0317 - val_acc: 0.9900\n",
      "Epoch 147/150\n",
      "50/50 - 0s - loss: 0.1258 - acc: 0.9406 - val_loss: 0.0397 - val_acc: 0.9875\n",
      "Epoch 148/150\n",
      "50/50 - 0s - loss: 0.1309 - acc: 0.9312 - val_loss: 0.0378 - val_acc: 0.9900\n",
      "Epoch 149/150\n",
      "50/50 - 0s - loss: 0.1279 - acc: 0.9362 - val_loss: 0.0354 - val_acc: 0.9850\n",
      "Epoch 150/150\n",
      "50/50 - 0s - loss: 0.1310 - acc: 0.9344 - val_loss: 0.0382 - val_acc: 0.9900\n"
     ]
    }
   ],
   "source": [
    "#ann model \n",
    "from tensorflow.python.keras import Sequential\n",
    "from tensorflow.python.keras.layers import Dense,Dropout\n",
    "\n",
    "model=Sequential([Dense(4,activation='relu'),\n",
    "                 Dropout(.3),\n",
    "                 Dense(16,activation='relu'),\n",
    "                 Dropout(.3),\n",
    "\n",
    "                 Dense(32,activation='relu'),\n",
    "                 Dropout(.3),\n",
    "\n",
    "                 Dense(1,activation='sigmoid'),\n",
    "                 \n",
    "                 ])\n",
    "model.compile(optimizer='adam', loss = 'binary_crossentropy',metrics=['acc'])\n",
    "history=model.fit(X_train, y_train,validation_data=(X_test,y_test), batch_size = 32, epochs = 150,verbose=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 432,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[347   1]\n",
      " [  2  50]]\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(X_test)\n",
    "y_pred = (y_pred > 0.5)\n",
    "\n",
    "# Making the Confusion Matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print(cm)\n",
    "#recall is 99.4 :)   it means validation set exampels are easy to the model val_acc > train_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
